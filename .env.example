# ./.env.example
# Example environment variables file.
# Copy this to .env and fill in your actual values.

# -------------------------------------
# --- Core Application Settings ---
# -------------------------------------
# !! CRITICAL: Generate a strong, random secret key for session security and encryption !!
# Use a command like: openssl rand -hex 32 OR python -c 'import secrets; print(secrets.token_hex(32))'
SECRET_KEY=generate_a_strong_random_32_byte_hex_key_here

# Set deployment mode: 'single' or 'multi'
# 'single': Uses global API keys, no login required (except for admin panel).
# 'multi': Requires user login, users manage their own API keys via the UI.
DEPLOYMENT_MODE=multi

# Set your preferred timezone (e.g., "UTC", "Europe/London", "America/New_York")
TZ=UTC

# Port the Flask app will be exposed on the host by Docker
APP_PORT=5004

# -------------------------------------
# --- API Keys (Global Fallbacks / Single-User Mode) ---
# -------------------------------------
# These are used globally in 'single' user mode.
# In 'multi' user mode, they serve as fallbacks if a user hasn't set their own.
ASSEMBLYAI_API_KEY=YOUR_ASSEMBLYAI_API_KEY_HERE # Used for AssemblyAI transcription
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE # Used for Whisper, GPT-4o Transcribe, and OpenAI LLMs
GEMINI_API_KEY=YOUR_GOOGLE_GEMINI_API_KEY_HERE # Used for Gemini LLM
ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY_HERE # Placeholder for future Anthropic LLM

# -------------------------------------
# --- Provider & Language Configuration ---
# -------------------------------------
# Default provider if not specified by user (options: "assemblyai", "whisper", "gpt-4o-transcribe")
DEFAULT_TRANSCRIPTION_PROVIDER=gpt-4o-transcribe
# --- LLM Provider & Model Configuration ---
# LLM_PROVIDER: "GEMINI" or "OPENAI". Determines which API is used.
LLM_PROVIDER=GEMINI
# LLM_MODEL: The specific model to use (e.g., "gemini-1.5-flash", "gpt-4o").
LLM_MODEL=gemini-2.0-flash
# Default language for transcription (e.g., "auto", "en", "es")
DEFAULT_LANGUAGE=auto
# Comma-separated list of supported language codes for the UI dropdown
SUPPORTED_LANGUAGE_CODES=en,nl,fr,es

# -------------------------------------
# --- MySQL Database Configuration ---
# -------------------------------------
MYSQL_HOST=mysql # Service name in docker-compose.yml for the app to connect to
MYSQL_PORT=3306  # Internal port the MySQL service listens on
MYSQL_USER=transcriber_user
MYSQL_PASSWORD=YOUR_STRONG_MYSQL_PASSWORD_HERE # Password for the 'transcriber_user'
MYSQL_DB=transcriber_db
MYSQL_ROOT_PASSWORD=YOUR_STRONG_MYSQL_ROOT_PASSWORD_HERE # Root password for the MySQL service itself
MYSQL_HOST_PORT=3307 # Port on the HOST machine to map to MySQL's internal port (for external access if needed)
# Database connection pool size
MYSQL_POOL_SIZE=10

# -------------------------------------
# --- Admin User (Initial Setup for 'multi' mode) ---
# -------------------------------------
ADMIN_USERNAME=admin
# !! CRITICAL: Set a strong password for the initial admin account !!
ADMIN_PASSWORD=YOUR_STRONG_ADMIN_PASSWORD_HERE
ADMIN_EMAIL=admin@example.com

# -------------------------------------
# --- Email Configuration (for Password Recovery etc.) ---
# -------------------------------------
MAIL_SERVER=smtp.example.com
MAIL_PORT=587
MAIL_USE_TLS=true
MAIL_USE_SSL=false
MAIL_USERNAME=your_email_username@example.com
MAIL_PASSWORD=your_email_password_or_app_password
MAIL_DEFAULT_SENDER="Transcriber Platform <noreply@example.com>"
MAIL_DEBUG=false # Set to true for verbose Flask-Mail logs

# -------------------------------------
# --- OAuth Configuration ---
# -------------------------------------
# Required for "Sign in with Google" feature in 'multi' mode
GOOGLE_CLIENT_ID=YOUR_GOOGLE_CLIENT_ID_FOR_WEB_APP.apps.googleusercontent.com

# -------------------------------------
# --- Workflow Configuration ---
# -------------------------------------
# Maximum number of tokens the LLM should generate in a workflow response
WORKFLOW_MAX_OUTPUT_TOKENS=1024
# Rate limit specifically for workflow API calls (example: "10 per hour" per user)
WORKFLOW_RATE_LIMIT="10 per hour"

# -------------------------------------
# --- File Storage & Data Retention ---
# -------------------------------------
# Time in seconds after which temporary uploaded files are deleted (default: 86400 = 24 hours)
DELETE_THRESHOLD=86400
# Number of days after a record is soft-deleted (hidden) before it's physically deleted from the database
PHYSICAL_DELETION_DAYS=120

# -------------------------------------
# --- Logging & Security ---
# -------------------------------------
LOG_LEVEL=INFO # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Complexity for password hashing (default: 12)
BCRYPT_LOG_ROUNDS=12
# Default rate limits for Flask-Limiter (applied to most non-auth routes)
RATELIMIT_DEFAULT="200 per day;50 per hour"
# RATELIMIT_STORAGE_URI="memory://" # Default in config.py, consider Redis for production

# -------------------------------------
# --- Transcription Performance ---
# -------------------------------------
# Number of parallel workers for chunked transcription (OpenAI models). AssemblyAI uses 1.
TRANSCRIPTION_WORKERS=4